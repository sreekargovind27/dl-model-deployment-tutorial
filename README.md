# Deep Learning Model Deployment Tutorial

A full-stack application demonstrating how to deploy multiple PyTorch models (MNIST CNN, ResNet18, MobileNetV2) using a Flask backend and a React frontend, deployed on Render.

### [➡️ Live Demo ⬅️](https://dl-model-deployment-tutorial.onrender.com)

## Overview

This project serves as a comprehensive, hands-on tutorial for deploying deep learning models as a web service. It covers the entire workflow from a trained model to a publicly accessible web application. The backend is built with Python and Flask, serving a REST API for predictions. The frontend is a modern, responsive interface built with React and Vite.

## Tech Stack

-   **Frontend:** React, Vite, CSS
-   **Backend:** Python, Flask, PyTorch, Gunicorn
-   **Package Management:** `uv` (Python), `npm` (Node.js)
-   **Deployment:** Render

## Project Structure

The repository is structured as a monorepo with distinct `backend` and `frontend` directories.


.

├── backend/

│ ├── data/ # Contains the raw MNIST dataset, used by train_mnist.py.

│ ├── data_imagenet/ # Contains imagenet_class_index.json for ImageNet model predictions.

│ ├── app.py # The main Flask application, defines API endpoints.

│ └── model_handler.py # Core logic for loading models and making predictions.

│

├── frontend/

│ └── src/ # React components and frontend source code.

│

├── models/ # Stores the trained model weights (.pth files).

│ └── mnist_cnn.pth # Generated by running train_mnist.py.

│

├── .gitignore

├── build.sh # A crucial build script for Render to build both frontend and backend.

├── pyproject.toml # The central configuration file for the Python project (metadata, dependencies).

├── README.md # You are here!

├── requirements.txt # A list of Python dependencies, for compatibility with some tools.

└── train_mnist.py # A script to train the MNIST CNN model from scratch.

Generated code
## Local Development Setup

Follow these steps to set up and run the project on your local machine.

### Step 1: Prerequisites

-   [Git](https://git-scm.com/)
-   [Python](https://www.python.org/downloads/) (3.8 or higher)
-   [Node.js](https://nodejs.org/en/) and npm

### Step 2: Clone the Repository

```bash
git clone https://github.com/sreekargovind27/dl-model-deployment-tutorial.git
cd dl-model-deployment-tutorial
```

### Step 3: Set Up Python Environment with uv

This project uses uv, an extremely fast Python package installer and resolver.


1. Install uv:
```bash
# On macOS and Linux:
curl -LsSf https://astral.sh/uv/install.sh | sh

# On Windows:
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

2. Create a Virtual Environment and Install Dependencies:

```bash
# Create a virtual environment named .venv
uv venv

# Activate the virtual environment
# On macOS/Linux:
source .venv/bin/activate
# On Windows (Command Prompt):
# .venv\Scripts\activate.bat

# Compile dependencies from pyproject.toml into requirements.txt
uv pip compile pyproject.toml -o requirements.txt

# Install the compiled dependencies from requirements.txt
uv pip install -r requirements.txt
```

### Step 4: Generate Required Model Assets

The application requires a trained model file to run. The train_mnist.py script is provided to train a simple Convolutional Neural Network (CNN) on the MNIST dataset.
1. **Why this step is needed:** The mnist_cnn.pth file contains the learned weights of our digit classification model. Without this file, the application cannot make predictions for the "MNIST CNN" option.
2. Run the training script:
```bash
# (From the root directory, with your virtual environment active)
python train_mnist.py
```

This command will:
- Automatically download the MNIST dataset into the backend/data/ folder.
- Train the CNN model.
- Save the final trained weights to models/mnist_cnn.pth.

### Step 5: Set Up the Frontend
```bash
# Navigate to the frontend directory
cd frontend

# Install Node.js dependencies
npm install

# Navigate back to the root directory
cd ..
```

### Step 6: Run the Application locally to test
You will need two separate terminals to run both the backend and frontend servers simultaneously.
- Terminal 1: Start the Backend (Flask) Server
    ```bash
    # (Make sure your virtual environment is activated)
    cd backend
    flask run --port 5001
    ```
The backend will be running at http://127.0.0.1:5001.

- Terminal 2: Start the Frontend (React) Server
    ```bash
    cd frontend
    npm run dev
    ```
The frontend development server will be running at http://localhost:5173. Open this URL in your browser.

## Deployment to Render

Follow these steps carefully to configure your service on the Render dashboard.

### Step 1: Create the Web Service

On your Render dashboard, click New + > Web Service and connect your GitHub repository.

### Step 2: Configure Build & Deploy Settings

This is the most important part. You must configure the settings to handle the monorepo structure.

**Root Directory:**
- Setting: Leave this field blank.
- Reason: Your build.sh script needs to access both the backend and frontend folders from the project root. Setting a root directory would limit Render's view to only that folder.
  
**Build Command:**

- Setting: bash ./build.sh
- Reason: This single command tells Render to execute your build script. The script handles the entire setup process: installing Python packages, installing Node.js packages, and building the static React app.
  
**Start Command:**

- Setting: gunicorn backend.app:app
- Reason: This command starts the production-ready Gunicorn server. It tells Gunicorn to look inside the backend folder for the app.py file and run the Flask instance named app.
  
**Auto-Deploy:**

- Setting: Set to Yes.
- Reason: This is highly recommended. It will automatically redeploy your application every time you push a new commit to your main branch, keeping your live demo up-to-date.
  
### Step 3: Deploy the Application

After saving your settings, trigger the first deployment.

1. Click Save Changes if you've edited an existing service.
2. Go to your service's dashboard and click Manual Deploy > Deploy latest commit.
3. You can monitor the progress in the Logs tab. Look for the success messages from your build.sh script (e.g., "Installing Python dependencies...", "Building frontend...").
   
Once the deployment is complete, your service will be live!












